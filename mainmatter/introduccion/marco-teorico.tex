\newpage 
\section{Marco te\'orico}
\subsection{Actividad f\'isica} \label{mt:af}
La Organización Mundial de la Salud \cite{who2019AFD} define actividad física como cualquier movimiento corporal producido por los músculos esqueléticos que exijan gastos de energías. Así mismo esta organización lista algunas variables de estudios que se deben considerar al momento de realizar cualquier tipo de actividad física:
\begin{itemize}
    \item \textbf{Duración:} Tiempo máximo que debe realizar la actividad física.
    \item \textbf{Frecuencia (repeticiones):} Número de veces que se realiza un ejercicio o actividad.
    \item \textbf{Ciclos (serie):} Cantidad de repeticiones en un lapso de tiempo continuo.
    \item \textbf{Volumen:} Cantidad total de repeticiones durante el tiempo de la actividad física.
\end{itemize}
\begin{chart}[H]
	\caption{Ejemplo de una actividad física de sentadillas}
	\label{chr:VariablesAF}
	\centering
	\includegraphics[width=150px,height=150px]{graphics/VariablesAF.png} \\
	\textbf{Fuente:} Propia
\end{chart}
Pongamos el caso de que un atleta realiza unas cantidades de repeticiones de sentadillas (actividad física) durante 80 segundos (duración) y un entrenador le está midiendo el tiempo acumulado por cada repetición que realiza el atleta a lo largo de dos series de 40 segundos de trabajo (ciclos). Al finalizar con la rutina, el entrenador realiza la gráfica  \ref{chr:VariablesAF}, en donde muestra que en promedio realiza 6  sentadillas por serie (frecuencia),  realizando un total de 12 sentadillas (volumen).
\medbreak
Dado el ejemplo, es importante conocer que la actividad física se realiza con la ayuda del sistema muscular, debido a que los músculos se pueden contraer para producir el movimiento de una persona (caminar, correr, nadar).
\subsection{Sistema muscular} \label{mt:sm}
De acuerdo al libro de fisiología y anatomía \cite{marieb2008anatomia}, los músculos se clasifican dependiendo de la ubicación en el cuerpo humano, entre ellos se encuentran los músculos que están unidos al esqueleto humano, la cual son sometidos al control de la persona (músculos voluntarios). Por lo tanto,  la investigación se centra en el estudio de los músculos esqueléticos, ya que son los músculos responsables en la producción del movimiento, mantenimiento de la postura y estabilización de las articulaciones \cite[p.~4]{marieb2008anatomia}.
\subsubsection{Contracción de un músculo esquelético en su conjunto} \label{mt:anafis:sm:ac:cont} \mbox{} \\
Durante la contracción muscular esquelética, se libera una molécula orgánica (nucleótido) llamada, \acrfull{ATP}, este nucleótido es el principal donador de energía en los sistemas biológicos  \cite{galindo2006energetica}, por lo tanto se considera como una fuente de energía que se puede usar directamente para alimentar la actividad muscular en tres formas distintas: \cite[p.~195]{marieb2008anatomia}:
\begin{enumerate}[1.]
    \item \textbf{Fosforilación directa:} Se genera grandes cantidades de moléculas de energía al momento de realizar una actividad intensa. (e.g. correr).
    \item \textbf{Respiración aeróbica:} Se genera una cantidad mínima de moléculas de energía al momento de que los músculos se encuentran en estado reposo o se realizan un ejercicio leve (e.g. caminar).
    \item \textbf{Glucólisis anaeróbico y formación de ácido láctico:} Se genera la demanda necesaria de moléculas de energía al momento de que los músculos se encuentran en una actividad moderada (e.g. trotar).
\end{enumerate}
Por otra parte, las producciones de energía están  presente al momento de realizar los siguientes movimientos corporales \cite[p.~199]{marieb2008anatomia}:
\begin{itemize}
	\item \textbf{Flexión:} Reduce el ángulo de la articulación, permitiendo acercar dos huesos entre sí (figura \ref{fig:MovimientoCorporales}.A).
	\item \textbf{Extensión:} Aumenta el ángulo de la articulación, permitiendo alejar dos huesos entre sí (figura \ref{fig:MovimientoCorporales}.A).
	\item \textbf{Rotación:} Es el movimiento de un hueso alrededor de un eje que parte la simetría del cuerpo, llamado eje longitudinal (figura \ref{fig:MovimientoCorporales}.B).
	\item \textbf{Abducción:} Consiste en mover una extremidad hacia fuera (figura \ref{fig:MovimientoCorporales}.C).
	\item \textbf{Aducción:} Consiste en mover una extremidad hacia dentro (figura \ref{fig:MovimientoCorporales}.C).
	\item \textbf{Circumducción:} Consiste en una combinación de movimientos de flexión, extensión, abducción y aducción, la cual permite mover una extremidad alrededor de todos los ejes, creando así movimientos circulares (figura \ref{fig:MovimientoCorporales}.C).
	\item \textbf{Flexión dorsal y flexión plantar:} Se le domina flexión dorsal cuándo se flexiona el pie sobre los talones mientras que la flexión plantar es lo opuesto al dorsal, debido que se flexiona el pie a partir de las puntas de los dedos. (figura \ref{fig:MovimientoCorporales}.D).
	\item \textbf{Inversión y eversión:} El movimiento inversión del pie consiste en mostrar la palma del pie al lado opuesto (e.g. la inversi\'on  del pie derecho conlleva mostrar la planta del pie derecho al lado izquierdo), mientras la eversión se muestra la palma del pie en lado correspondiente (figura \ref{fig:MovimientoCorporales2}.E).
		\item \textbf{Supinación y pronación:} Movimiento de rotación del radio y cúbito (huesos correspondiente al antebrazo), en donde la supinación consiste en mostrar la palma de la mano al lado opuesto (e.g. la supinación de la mano derecha conlleva mostrar la planta de la mano derecha al lado izquierdo), mientras la pronación se muestra la palma de la mano en lado correspondiente (figura \ref{fig:MovimientoCorporales2}.F).
		\item \textbf{Oposición:} Movimiento de los dedos de las manos, la cual permiten que el dedo gordo permita tocar las puntas de los otros dedos de la misma mano (figura \ref{fig:MovimientoCorporales2}.G).
\end{itemize} 
\begin{figure}[H]
	\caption{Movimientos corporales de los músculos esqueléticos}
	\label{fig:MovimientoCorporales}
	\centering
	\includegraphics[width=475px,height=280px]{graphics/MovimientosCorporales.jpg} \\
	\textbf{Fuente:} \citeA[p.~200]{marieb2008anatomia}
\end{figure}
\begin{figure}[H]
	\caption{Continuación de movimientos corporales de los músculos esqueléticos}
	\label{fig:MovimientoCorporales2}
	\centering
	\includegraphics[width=475px,height=280px]{graphics/MovimientosCorporales2.jpg} \\
	\textbf{Fuente:} \citeA[p.~200]{marieb2008anatomia}
\end{figure}
Finalmente, los movimientos corporales de los músculos esqueléticos se pueden aplicar al área deportiva al momento de realizar un movimiento deportivo.
\subsection{Movimiento deportivo} \label{mt:mf}
De acuerdo a una guía de entrenamientos para distintos ejercicios \cite{crossfitinc2019}, el movimiento deportivo busca utilizar todas las extremidades del cuerpo humano de manera eficiente y natural.
\medbreak
Por otra parte el estudio de posturas y deporte \cite{pomes2008postura}, menciona que cada profesional deportivo ayuda al atleta a aprender correctamente el gesto deportivo para prevenir lesiones en el cuerpo y además de tener un movimiento deportivo correcto a partir de las  posiciones correctas de los pasos de un movimiento.
\medbreak
En cuanto a la ejecución de un movimiento deportivo, es importante realizar el calentamiento previamente, la cual consta en realizar movimientos corporales (flexiones, rotaciones, extensiones), con el fin de objetivo de preparar el cuerpo para rendir al máximo y prevenir futuras lesiones \cite{calDeportivo}.
\medbreak
Adem\'as el movimiento deportivo lo ha utilizado médicos, entrenadores, deportistas y otros profesionales, con la finalidad de realizar distintos estudios, un ejemplo claro son los doctores Bruce Evans y Jim Cawley, fundadores del entrenamiento con una pelota medicinal \cite{DynamaxMedicine}, la cual propusieron  analizar al atleta por las siguientes habilidades físicas: 
\begin{itemize}
	\item \textbf{Resistencia cardiovascular o respiratoria:} Capacidad que tiene el cuerpo humano de procesar y entregar oxígeno.
	\item \textbf{Resistencia muscular:} Procesamiento y almacenamiento de energía en el cuerpo humano.
	\item \textbf{Fuerza:} Unidad muscular para mover una carga.
	\item \textbf{Flexibilidad:} Rango del movimiento muscular.
	\item \textbf{Velocidad:} Tiempo de un ciclo de un movimiento.
	\item \textbf{Coordinación:}  Habilidad de combinar varios pasos de un movimiento.
	\item \textbf{Agilidad:} Tiempo de transición entre dos pasos de un movimiento.
	\item \textbf{Balance:} Centro de apoyo para realizar el movimiento.
	\item \textbf{Precisión:} Dirección recomendada  para realizar los pasos de un movimiento.
\end{itemize}
Al mismo tiempo, las habilidades físicas se pueden analizar para cualquier tipo de movimiento, como por ejemplo, press con mancuerna, la cual consta en levantar un peso por arriba de la cabeza:
\begin{figure}[H]
	\caption{Análisis de habilidades físicas del movimiento: Press con mancuerna}
	\label{fig:HabilidadesFisicas}
	\centering
	\includegraphics[width=450px,height=200px]{graphics/habilidadesFisicas.jpg} \\
	\textbf{Fuente:} Propia
\end{figure}
En la figura de análisis de habilidades físicas del movimiento: Press con mancuerna, se muestra los pasos requeridos para realizar el movimiento (coordinación), y al mismo tiempo se dibuja una flecha guía que muestra la dirección recomendada para ejecutar las transiciones de los pasos 1 al 2 (precisión), cabe resaltar que las restantes habilidades físicas se pueden analizar a partir de entrenamientos por intervalos controlados.

\subsubsection{Entrenamientos por intervalos controlados} \label{mt:mf:rut}
Según la Real Academia Española define rutina como una costumbre o hábito adquirido por la práctica, por otro lado la definición en el área deportiva es muy similar, ya que en una rutina deportiva se centra en mejorar las habilidades físicas del atleta \cite{crossfitinc2019} a partir de intervalos de movimientos, tomando en cuenta las capacidades físicas de la persona para realizar ejercicios de alta intensidad llamados,  \acrfull{HIIT}.
\medbreak
Por otro lado, los investigadores    \citeA{cofre2016entrenamiento}, realizaron un artículo científico del entrenamiento de alta intensidad, en ella describe que estos entrenamientos son desarrollados por los entrenadores debido que conocen las habilidades físicas de sus atletas, un ejemplo claro son los entrenadores olímpicos estadounidenses, Lawson Robertson y Dean Cronwell, que efectuaron entrenamientos divididos en tramos de alta velocidad y otros tramos para obtener la recuperación de sus atletas durante las juegos olímpicos de 1928. Así mismo en los años 1910 a 1912, el entrenador, Lauri Pihkala, desarrolló un sistema finlandés de entrenamiento, la cual constaba en que un atleta realizaba hasta 5 repeticiones de un movimiento y en cada repetición recorría una distancia de 200 metros con tiempos de descanso. 
\medbreak
Por lo tanto se puede concluir que los entrenamientos por intervalos se pueden realizar de distinta forma para buscar la intensidad del atleta, entre ellos se pueden encontrar \cite{gseWOD}:
\begin{itemize}
	\item \textbf{Por tiempo:} Entrenamiento donde el atleta debe realizar las repeticiones que le sea posible hacer en el tiempo asignado (e.g. durante 2 minutos hacer sentadillas).
	\item \textbf{Por repeticiones:} Entrenamiento donde el atleta debe realizar las repeticiones asignadas (e.g. realizar un total de 50 sentadillas). 
	\item \textbf{Tabata:} Entrenamiento que consta de tiempos de trabajos y de descansos, la cual el atleta debe realizar la cantidad de repeticiones que es posible hacer durante el tiempo de trabajo y posteriormente debe recuperarse durante un tiempo corto de descanso (e.g. tabata de sentadillas durante 1 minuto con tiempo de descanso de 20 segundos).
\end{itemize} 
Estas rutinas permiten trabajar las habilidades físicas del atleta durante un período corto, además de controlar y medir distintas variables deportivas, como las repeticiones de un movimiento deportivo \cite{foodspring}, tal como se observa en el ejemplo del entrenamiento tabata del movimiento, press con mancuerna:
\begin{chart}[H]
	\caption{Ejemplo del entrenamiento tabata del movimiento, press con mancuerna}
	\label{chr:tabataSentadilla}
	\centering
	\includegraphics[width=400px,height=150px]{graphics/hiitMf.jpg} \\
	\textbf{Fuente:} Propia
\end{chart}
Pongamos el caso que un entrenador le programa a su atleta un tabata de 60 segundos de trabajo y de descanso, durante 4 series del movimiento, press con mancuerna, as\'i mismo a lo largo de las series de trabajo, el entrenador contabiliza las repeticiones del movimiento del atleta y al finalizar la rutina, realiza la gráfica \ref{chr:tabataSentadilla}, la cual se puede concluir que el atleta puede realizar un máximo de 11 repeticiones del movimiento en un lapso de un minuto (velocidad por serie) y en promedio tarda 6 segundos en realizar un press con mancuerna (velocidad por repetición). Finalmente se puede ver la resistencia muscular, debido que durante la primera y cuarta serie, la persona procesa un alto consumo de energía ya que realiza una mayor cantidad de repeticiones por minuto, en comparación con las series intermedias.
\subsection{C\'amara con sensor de profundidad} \label{mt:cam}
De acuerdo con  \citeA{carfagni2017performance} y su estudio enfocado en el rendimiento de la  cámara Intel SR300, las principales funciones de las \acrfull{RGBD}  son la adquisición y procesamientos de datos en \acrfull{TRESD}, utilizándose tanto en el sector industrial como académico (e.g. reconocimiento de posiciones, gestos y objetos).
\medbreak
Por otro lado los autores, \citeA{henry2012rgb}, investigaron las variables necesarias para realizar un mapeo del ambiente (RGB-D mapping), siendo analizadas por medio de \gls{pixeles} de información de imágenes a color y de profundidad, tal como se muestra en la figura \ref{fig:RGBD}:
\begin{figure}[H]
	\caption{Captura de datos de una c\'amara con sensor de profundidad}
	\label{fig:RGBD}
	\centering
	\includegraphics[width=220px,height=160px]{graphics/RGB-D.jpg} \\
	\textbf{Fuente:} Propia
\end{figure}
La figura \ref{fig:RGBD}, fue capturada por el dispositivo Kinect de XBox One, a una velocidad de 28 \acrfull{FPS}, por otro lado en la figura de la  izquierda se tiene una vista a escalas de grises, mientras que del lado derecho se tiene una vista de datos de profundidad, por lo tanto en ambas imágenes se pueden capturar distintas variables de análisis (e.g. distancia, seguimiento y color de objetos).
%\todo[inline]{hasta aca llevo 5 veces "cabe mencionar", para que el texto sea fluido debes variar los conectores de discurso}
%\todo[inline]{los i.e. y e.g no se combinan con paréntesis -i.e. es una anotación independiente-}
%\todo[inline]{cuando uses e.g no se puede utilizar " y más, entre otros, etc. " se sobre entiende que e.g. es un subconjunto}
\subsubsection{Dispositivos en el mercado} \label{mt:cam:mer}
A continuación se presentará una lista de cámaras con sensor de profundidad, que se encuentran en el mercado hoy en día:
\begin{itemize}
	\item \textbf{ASUS XtionPro Live:} La corporación, Asustek Computer \cite{xtionAsus}, desarrolló una cámara con sensor de profundidad e infrarrojo, que permite detectar profundidad adaptativa, imagen a color y flujo de audio.
	\item \textbf{Structure Sensor:} La empresa, Occipital Inc \cite{structureOccipital}, implementó un sensor de estructura, que permite escanear las personas, los espacios y los objetos en 3D. 
	\item \textbf{Intel RealSense cameras:} La empresa \citeA{intelRealSense}, desarrolló un producto de cámaras que permite detectar una alta velocidad de fotogramas, color de calidad y una resolución de profundidad. De igual manera las cámaras de Intel se han utilizado en soluciones innovadoras (e.g. rob\'otica, drones, realidad virtual).
	\item \textbf{Microsoft Kinect:} De acuerdo con el autor	\citeA{zhang2012microsoft} y su análisis de los componentes del Kinect, se conforma por un sensor de profundidad, una cámara a color y una matriz de micrófonos que permite capturar movimientos, reconocer características faciales, construir un modelo del cuerpo en 3D y reconocer sonidos.
\end{itemize}
Como se observa en el listado, todas las cámaras con RGB-D tiene características similares que permite detectar elementos en el ambiente, sin embargo a la hora de escoger una cámara se debe tomar en cuenta las siguientes especificaciones \cite{zhang2012microsoft}:
\begin{itemize}
	\item \textbf{Alcance del sensor 3D:} Distancia de profundidad máxima que puede detectar un objeto (Figura \ref{fig:RGBESP}.A).
	\item \textbf{Campo de visión:} Ángulo máximo de visión respecto al eje horizontal (H, figura \ref{fig:RGBESP}.B.1),  y al eje vertical (V,  figura \ref{fig:RGBESP}.B.2).
	\item \textbf{Resolución de la imagen:} Cantidad de detalle que puede observarse en las imágenes de infrarrojo o de color (e.g. figura \ref{fig:RGBD}).
	\item \textbf{Conexión:} Canal de comunicación entre la cámara y el dispositivo electrónico (figura \ref{fig:RGBESP}.C).
\end{itemize}
%\todo[inline]{Aca es un buen lugar para que agreges una pequeña definición de cada especificación/variable importante, un lector poco familizarizado esperaria eso en este momento}
\begin{figure}[H]
	\caption{Especificaciones de una c\'amara con RGB-D}
	\label{fig:RGBESP}
	\centering
	\includegraphics[width=300px,height=170px]{graphics/RGBFeatures.png} \\
	\textbf{Fuente:} Propia
\end{figure}
\medbreak
A continuación se presentará una comparación de las especificaciones entre las cámaras de RGB-D, mencionadas anteriormente:
\begin{table}[H]
\begin{center}
\caption{Comparación de especificaciones entre cámaras de RGB-D }
\label{tab:RGBD}
\begin{tabular}{|l|l|l|l|l|l|} 
\hline
\textbf{Características}                                                          & \begin{tabular}[c]{@{}l@{}}\textbf{ASUS}\\\textbf{XtionPro}\\\textbf{Live}\end{tabular}   & \begin{tabular}[c]{@{}l@{}}\textbf{Structure}\\\textbf{Sensor}\end{tabular}  & \begin{tabular}[c]{@{}l@{}}\textbf{Intel}\\\textbf{RealSense}\\\textbf{SR300}\end{tabular}  & \begin{tabular}[c]{@{}l@{}}\textbf{Microsoft}\\\textbf{Kinect}\\\textbf{Live}\end{tabular} & \begin{tabular}[c]{@{}l@{}}\textbf{Microsoft}\\\textbf{Kinect}\\\textbf{v2}\end{tabular}	  \\ 
\hline
\begin{tabular}[c]{@{}l@{}}\textbf{Alcance del}\\\textbf{ sensor 3D}\end{tabular} & 0.8 a 3.5 m                                                                               & 0.4 a 3.5m                                                                   & 0.2 a 1.5m                                                                                  & 1.8 a 3.5m                                                                                 & 1.3 a 3.5m                                                                                  \\ 
\hline
\textbf{3D Resolución}                                                            &\begin{tabular}[c]{@{}l@{}}640x480\\30fps\end{tabular}                   & \begin{tabular}[c]{@{}l@{}}640x480\\30fps\end{tabular}     & \begin{tabular}[c]{@{}l@{}}640x480\\60fps\end{tabular}                    &\begin{tabular}[c]{@{}l@{}}320x240\\30fps\end{tabular}					& \begin{tabular}[c]{@{}l@{}}512x424\\30fps\end{tabular}                    \\ 
\hline
\begin{tabular}[c]{@{}l@{}}\textbf{RGB}\\\textbf{ Resolución}\end{tabular}        &\begin{tabular}[c]{@{}l@{}}1280x1024\\30fps\end{tabular}                   & \begin{tabular}[c]{@{}l@{}}640x480\\30fps\end{tabular}     & \begin{tabular}[c]{@{}l@{}}1920x1080\\30fps\end{tabular}                    &\begin{tabular}[c]{@{}l@{}}640x480\\30fps\end{tabular}					& \begin{tabular}[c]{@{}l@{}}1920x1080\\30fps\end{tabular}                    \\ 
\hline
\textbf{FOV}                                                                      & 58°H, 45°V                                                                                & 58°H, 45°V                                                                   & 73°H, 59°V                                                                                  & 57°H, 43°V                                                                                 & 70°H, 60°V                                                                                  \\ 
\hline
\textbf{Conexión}                                                                 & USB 2.0                                                                                   & USB 2.0                                                                      & USB 3.0                                                                                     & USB 2.0                                                                                    & USB 3.0                                                                                     \\
\hline
\end{tabular}
\end{center}
\textbf{Fuente:} Desarrollo de una aplicación interactiva con Intel RealSense \cite{molero2018desarrollo} y la evaluación de la precisi\'on de resoluci\'on espacial del sistema de seguimiento facial para Kinect para windows v1 y v2
 \cite{amon2014evaluation}
\end{table}
\medbreak
En la tabla \ref{tab:RGBD}, se puede determinar que las cámaras: Intel RealSense SR300 y Microsoft Kinect V2, destacan de las demás cámaras, debido  que tiene una mayor resolución del sensor RGB y un campo de visión más amplio, por lo cual para el presente proyecto se seleccionará la cámara Microsoft Kinect V2, debido que satisface todos los requisitos del proyecto (e.g. seguimiento del esqueleto, campo visi\'on aceptable y resoluci\'on de imagen aceptable),  adem\'as de ser un producto de f\'acil adquisici\'on en la ciudad de Guatemala.
\subsubsection{Microsoft Kinect V2} \label{mt:cam:kin}
En la guía de programación de Kinect para Windows SDK \cite{jana2012kinect}, da a conocer características del sensor Kinect, entre ellas se pueden mencionar que el sensor Kinect se desarrolló para la consola de videojuegos, Xbox 360, además proporcionan una \acrfull{NUI} (tecnología con control de manos libres), que permite interactuar con el dispositivo a partir de movimientos, gestos y sonidos.
\medbreak
Por otra parte \citeA{jana2012kinect} describe el \acrfull{SDK} del Kinect, desarrollado para distintos lenguajes de programación (C++, c\#, python), siendo necesario conocer la arquitectura del Kinect para su uso e implementación.
\\
\paragraph{Componentes} \label{mt:cam:kin:comp} \mbox{} \\
\citeA{jana2012kinect} menciona los principales componentes del sensor Kinect:
\begin{itemize}
	\item \textbf{Cámara a color:} Permite capturar y transmitir los datos de vídeo en color (Figura \ref{fig:COMPKINECT}.A).
	\item \textbf{Sensor de profundidad:} Este sensor est\'a conformado por un emisor de infrarrojo, que se encarga de escanear el ambiente constantemente y convertirlo en información a partir del sensor de profundidad infrarroja (Figura \ref{fig:COMPKINECT}.B).
	\item \textbf{Motor:} Rota la imagen en tiempo real (Figura \ref{fig:COMPKINECT}.C).
	\item \textbf{Matriz de micrófonos:} Captura e identifica la dirección del sonido en el ambiente (Figura \ref{fig:COMPKINECT}.D).
	\item \textbf{Diodo de emisor de luz (LED) de controladores:} Identifica si los controladores del Kinect (Seguimiento de objeto, RGB o sonido) están funcionando  correctamente (Figura \ref{fig:COMPKINECT}.E).
\end{itemize}
\begin{figure}[H]
	\caption{Componentes del Kinect V2}
	\label{fig:COMPKINECT}
	\centering
	\includegraphics[width=400px,height=300px]{graphics/kinect-parts.jpg} \\
	\textbf{Fuente:} Propia
\end{figure}
\medbreak
%\todo[inline]{Aca nuevamente seria mejor dar una descripción general de cada componente en un listado que permita entender de forma facil cada uno de los elementos}
\paragraph{Conexión a la computadora} \label{mt:cam:kin:con} \mbox{} \\
\begin{figure}[H]
	\caption{Adaptador del Kinect V2}
	\label{fig:ADAPTERKINECT}
	\centering
	\includegraphics[width=400px,height=170px]{graphics/adapter-kinect.jpg} \\
	\textbf{Fuente:} \citeA{Kinectmanual}
\end{figure}
\medbreak
Tal como se observa en la figura \ref{fig:ADAPTERKINECT}, el cable de conexión est\'a conformado por 5 partes: (1) el cable de datos del Kinect que se encarga de recibir los datos de entradas y salidas del sensor, así mismo esta (2) el adaptador del Kinect, que permite administrar los datos de entradas y salidas de la computadora y el sensor, a partir del (3) cable de USB 3. Igualmente el adaptador funciona con  un voltaje de 12 voltios y una corriente de 3 amperios que son administrado de una (4-5) fuente de alimentación  que regula una entrada de 100 a 240 voltios y una corriente de 1.6 amperios.
\paragraph{Kit de desarrollo de Software (SDK)} \label{mt:cam:kin:sdk} \mbox{} \\
Para el presente proyecto se utilizará el SDK de la empresa  \citeA{SDKKinect}, este SDK permite crear aplicaciones de reconocimientos de gestos y de voz con el sensor Kinect.
Cabe destacar que para realizar estas aplicaciones, es necesario entender la interacción del software y del hardware:
\begin{figure}[H]
	\caption{Interacción del software y hardware}
	\label{fig:interaccionKinect}
	\centering
	\includegraphics[width=400px,height=180px]{graphics/interacionKinect.png} \\
	\textbf{Fuente:} Propia
\end{figure}
En la figura \ref{fig:interaccionKinect}, se puede observar que el sensor kinect maneja 3 transmisiones de datos de salidas:
\begin{itemize}
	\item \textbf{Datos de la imagen a color:} Según el estudio de los códigos de fuentes del SDK del Kinect \cite{hernandez2013analisis}, mencionan que los datos de imagen a color trabajan con un nivel de calidad que determina la velocidad en que los datos son transferidos (fotogramas por segundos), por otro lado permiten conocer el formato en que est\'a enviando dicha información: RGB (mapa de bits a color de 32 bits) o YUV (mapa de bits a color de 16 bits con corrección de transparencia de imagen).
	\item \textbf{Datos de cámara de profundidad:}  \citeA{hernandez2013analisis}, explican que el sensor de profundidad almacena una escala de grises de todo el campo visible en un conjunto de píxeles que representan una distancia de cercanía con la cámara (base, altura y profundidad), también la información es almacenado en 2 bytes, la cual un byte corresponde al emisor de IR y el otro byte corresponde al sensor de profundidad IR.
	\item \textbf{Datos del sonido:} Según el libro de detección de movimiento y profundidad para NUI \cite{rahman2017beginning}, habla sobre la transmisión del sonido, en donde se captura en un rango máximo de 180 grados, así mismo la información es almacenada en un vector de byte (e.g. Waveformat, estructura básica de 16 bytes).
\end{itemize}
Al mismo tiempo las transmisiones  interactúan a través del recurso, NUI, dicho recurso est\'a compuesto por los siguientes elementos:
\begin{figure}[H]
	\caption{Arquitectura del software, Kinect-NUI}
	\label{fig:architecturesSoftwareKinect}
	\centering
	\includegraphics[width=390px,height=300px]{graphics/kinect-software-architecture.PNG} \\
	\textbf{Fuente:} \citeA[p.~14]{giori2013kinect}
\end{figure}
En el Libro, Kinect en  movimiento \cite{giori2013kinect}, da a conocer los elementos que trabajan en el NUI  (figura \ref{fig:interaccionKinect}):
\begin{enumerate}[1.]
    \item \textbf{Kinect sensor:} Administra la conexión y los componentes del hardware.
    \item \textbf{Kinect drivers:} Gestiona los controladores necesarios para el funcionamiento del Kinect (e.g. arreglos de audio, cámaras, dispositivos y seguridad), además los controladores son accesible en el directorio de controladores dentro de la carpeta "kinectsensor.inf".
    \item \textbf{NUI API:} Administra los componentes de SDK (Rastreo de esqueleto, audio, imagen de profundidad y de color), igualmente los componentes son accesible en el directorio del Kinect (Ubicado en el directorio de archivos de programas del sistema operativo).
    \item \textbf{Directx media object (DMO):} Se encarga del funcionamiento de la matriz del audio (e.g. Identificar y analizar el origen de la fuente del audio).
    \item \textbf{Windows standar API:} Proporciona componentes complementarios del funcionamiento del sensor(e.g. Microsoft.speech, system.media).
\end{enumerate}
%\todo[inline]{Una vez que mencionaste que son elementos, no vale la pena volver a poner elemento en cada definición}
\subparagraph{Kinect v2 configuration verifier
} \label{mt:cam:kin:kcv} \mbox{} \\
Dicha aplicación verifica y analiza el dispositivo que se encuentra conectado al sensor Kinect, tomando en cuenta las compatibilidades del hardware y la comunicación del dispositivo al sensor:
\begin{figure}[H]
	\caption{Kinect v2 configuration verifier}
	\label{fig:KinectConfigurationVerifier}
	\centering
	\includegraphics[width=360px,height=300px]{graphics/kinect-configuration-verifier.jpg} \\
	\textbf{Fuente:} Propia
\end{figure}
\medbreak
En la figura \ref{fig:KinectConfigurationVerifier}, se observa las siguientes validaciones:
\begin{itemize}
	\item \textbf{Update configuration definitions:} Verifica que tenga la última versión del SDK (V.2).
		\item \textbf{Operating system:} Comprueba si el sistema operativo es compatible (Windows 8 o superior).
		\item \textbf{Processor cores:} Detecta si el procesador tiene los suficientes números de n\'ucleos.
		\item \textbf{Physical memory (RAM):} Chequea si el dispositivo tiene la suficiente memoria (mínimo 4GB de RAM).
		\item \textbf{Graphics processor:} Revisa si el procesador gráfico es compatible con el SDK. 
		\item \textbf{USB controller:} Verifica si el dispositivo reconoce el puerto de entrada.
		\item \textbf{Kinect connected:} Examina si el Sensor Kinect se encuentra conectado con el dispositivo.
		\item \textbf{Verify kinect software installed:} Reconoce los controladores (drives) del sistema y el sensor.
		\item \textbf{Verify kinect depth and color streams:} Muestran el funcionamiento de los sensores de profundidad y de color.
\end{itemize}
\subparagraph{Kinect Studio} \label{mt:cam:kin:ks} \mbox{} \\
En el libro de detección de movimiento y profundidad para NUI \cite{rahman2017beginning}, trabaja con algunas aplicaciones ya implementadas en el SDK, entre ellas se pueden mencionar, Kinect Studio, aplicación que permite capturar y reproducir datos del sensor en formato de vídeo, además los datos son administrados por los siguientes monitores:
\begin{itemize}
	\item \textbf{Monitor NUI body frame:} Contiene un espacio de almacenamiento para trabajar los datos de articulaciones del cuerpo.
	\item \textbf{Monitor NUI body index:} Se encarga de asignar un identificador a cada cuerpo que reconoce el Monitor NUI body frame.
	\item \textbf{Monitor NUI depth:} Organiza los datos de profundidad (eje z).
	\item \textbf{Monitor NUI IR:} Administra la imagen infrarroja a partir de la técnica de \gls{TOF}.
	\item \textbf{Monitor NUI title audio:} Suministra el audio capturado en todas las direcciones.
	\item \textbf{Monitor NUI uncompressed color:} Proporciona los datos de color.	
\end{itemize}
Estos datos son almacenados en un formato de  \acrfull{XEF}, dicho formato genera un vídeo de gran tamaño debido a la cantidad de datos que son capturados por los monitores, por lo cual se recomienda realizar varias repeticiones del movimiento en el menor tiempo posible y de igual manera capturar los siguientes datos para el análisis del movimiento:
\medbreak
\begin{figure}[H]
	\caption{Diagrama de venn para la identificación del movimiento de un objeto}
	\label{fig:VennStreaming}
	\centering
	\includegraphics[width=220px,height=150px]{graphics/venn-streaming.jpg} \\
	\textbf{Fuente:} Propia
\end{figure}
\medbreak
En la figura \ref{fig:VennStreaming}, se puede observar que los monitores: Body frame, depth e IR, trabajan conjuntamente para reconocer el seguimiento del esqueleto, así mismo es importante obtener los datos correctos por medio de la calibración de datos y disponibilidad de la información en todo momento (Telemetría).
\medbreak
Finalmente en la figura \ref{fig:PlayKinectStudio}, se observa el resultado de un vídeo tomado por la aplicación Kinect studio, así mismo la aplicación proporciona varias herramientas para analizar el vídeo, tales como: puntos de interrupciones (pausa, inicio y fin de un segmento), por otro lado se puede indicar el número de repeticiones de una  interacción (cantidad de veces que se desea ver un segmento del v\'ideo), además de agregar los  metadatos de un fotograma, cuya funci\'on es  almacenar información adicional en un punto específico del vídeo.
%\todo[inline]{Escribir siempre en tercera persona}
 \begin{figure}[H]
	\caption{Visualización del vídeo, Kinect Studio}
	\label{fig:PlayKinectStudio}
	\centering
	\includegraphics[width=400px,height=280px]{graphics/play-kinectstudio.jpg} \\
	\textbf{Fuente:} Propia
\end{figure}
\subparagraph{Visual Gesture Builder} \label{mt:cam:kin:vgb} \mbox{} \\
El libro de detección de movimiento y profundidad para NUI \cite{rahman2017beginning}, trabaja con una aplicación de aprendizaje automático llamada: \acrfull{VGB}, que permite crear una base de datos que reconocen los gestos en tiempo de ejecución llamado, \acrfull{GDB}, con respecto a esta herramienta se utiliza dos algoritmos para la detección de movimiento, \acrfull{RFR} para modelos continuos, y \acrfull{AdaBoost} para modelos discretos. Se debe tomar en cuenta que estos  algoritmos analizan las variables de un movimiento cinemático \cite{mcginnis2013biomechanics}:
\begin{itemize}
	\item \textbf{Posición:} Localización de articulaciones en el espacio definido por el sensor Kinect.
	\item \textbf{Desplazamiento:} Distancia recorrida de una articulación respecto a una posición inicial y final.
	\item \textbf{Ángulos de articulaciones y de movimientos:} Flexibilidad de movimiento que tiene una articulación.
	\item \textbf{Velocidad lineal y angular:}  Desplazamiento y arco de movimiento de una articulación divido el tiempo que tomó para desplazarse.
	\item \textbf{Aceleración lineal y angular:} Tasa de cambio de velocidad de una articulación.
	\item \textbf{Fuerza muscular:} Empuje o tirón que deforma el músculo al momento que se contrae.
	\item \textbf{Torque muscular:} Analiza la fuerza de un músculo respecto a la distancia del tendón.
\end{itemize}
Por lo que se refiere al modelo AdaBoost el autor, \citeA{AdaBoosting2018}, realiz\'o un artículo científico sobre la técnica de boosting, la cual consta en mejorar las predicciones del modelo, a partir de un número de entrenamientos secuenciales:
\begin{figure}[H]
	\caption{Técnica boosting}
	\label{fig:AdaBoost}
	\centering
	\includegraphics[width=400px,height=200px]{graphics/AdaBoosting.jpg} \\
	\textbf{Fuente:} Propia
\end{figure}
\medbreak
En la figura \ref{fig:AdaBoost}, se observa que en el entrenamiento No. 1,  los datos de entradas se encuentran muy dispersos, por lo tanto, cada dato de entrada se  debe entrenar a partir de un algoritmo de aprendizaje, que permite obtener una nueva función, tal como se observa el entrenamiento No. 2, los datos de entradas están más cercanos. De igual forma se debe establecer los números de entrenamientos y los algoritmos de aprendizajes que se utilizarán por cada entrenamiento, siguiendo con el ejemplo de la figura \ref{fig:AdaBoost}, tiene un total de 2 entrenamientos, y cada entrenamiento consta de operar el dato de entrada por su respectiva regresión lineal y una constante.
\medbreak
En efecto el modelo discreto es recomendable utilizarlo para identificar movimientos estáticos (e.g. de pie, sentado, acostado), por lo que el software, Visual Gesture Builder, permite analizar el vídeo (.xef) y posteriormente etiqueta los momentos que se encuentran realizando los  movimientos estáticos:
\begin{figure}[H]
	\caption{Etiquetas de movimientos estáticos}
	\label{fig:modeloDiscreto}
	\centering
	\includegraphics[width=400px,height=350px]{graphics/modelo-discreto.jpg} \\
	\textbf{Fuente:} Propia
\end{figure}
\medbreak
En la figura \ref{fig:modeloDiscreto}, se puede observar que en el panel de control (figura \ref{fig:modeloDiscreto}.A) puede etiquetar los valores: Verdaderos (barra arriba) y falsos (barra abajo). Así mismo se observa el movimiento estático, manos abajo, que consta en identificar que ambas manos y brazos estén tocando la parte dorsal del (figura \ref{fig:modeloDiscreto}.B), en caso que est\'e realizando otro movimiento, el valor de la etiqueta será falso (i.e.  Figura \ref{fig:modeloDiscreto}.C).
\medbreak
Por lo que se refiere al modelo de Random Forest Regression,   \citeA{RandomForestRegression2018} realizó un artículo científico sobre este algoritmo, la cual separa el procedimiento en dos partes, la primera parte consta de la aleatoriedad, que permite que una variable de entrada puede estar presente o no (creando distintas combinaciones de sets de entradas). La segunda parte consta de un conjunto de \'arboles de decisiones que son entrenados de acuerdo a la aleatoriedad de cada set de entradas, posteriormente hay una funci\'on de activaci\'on que recolecta la regresi\'on de cada \'arbol, para obtener el resultado del pron\'onostico :
\begin{figure}[H]
	\caption{Algoritmo de Random Forest Regression}
	\label{fig:RandomForestRegression}
	\centering
	\includegraphics[width=400px,height=170px]{graphics/random-forest-regression.png} \\
	\textbf{Fuente:} Propia
\end{figure}
\medbreak
Finalmente, el modelo continuo es recomendable utilizarlo para identificar movimientos continuos (e.g. sentadillas, abdominales, saltos), tal como se observa en la figura de etiquetado de un movimiento din\'amico:
\begin{figure}[H]
	\caption{Etiquetas de movimientos dinámicos}
	\label{fig:modeloContinuo}
	\centering
	\includegraphics[width=400px,height=250px]{graphics/modelo-continuo.jpg} \\
	\textbf{Fuente:} Propia
\end{figure}
En la figura \ref{fig:modeloContinuo}, est\'a analizando el movimiento de vuelo, la cual se conforma de tres movimientos estáticos: Brazos abajo (figura \ref{fig:modeloContinuo}.B), brazos al medio (figura \ref{fig:modeloContinuo}.C)  y brazos arriba (figura \ref{fig:modeloContinuo}.D),  por lo tanto para analizar y detectar el movimiento dinámico, se etiqueta con un valor decimal a cada movimiento estático, tal como se observa en el panel de control (figura \ref{fig:modeloContinuo}.A), las etiquetas del primer paso tiene un valor de 0 (todos los puntos de  abajo), las etiquetas del segundo paso tiene un valor de 0.5 (todos los puntos del medio), y finalmente las etiquetas del tercer paso tiene un valor de 1 (todos los puntos de arriba).
\subparagraph{Seguimiento del esqueleto} \label{mt:cam:kin:st} \mbox{} \\
De acuerdo al análisis y estudio de los códigos de fuentes de SDK del Kinect \cite{hernandez2013analisis}, menciona el funcionamiento del seguimiento del esqueleto, en donde se genera la figura humana a través de 25 puntos que representan las principales articulaciones del cuerpo, tal como se muestra en la figura \ref{fig:jointsKinect}:
\begin{figure}[H]
	\caption{Seguimiento de uniones del Kinect}
	\label{fig:jointsKinect}
	\centering
	\includegraphics[width=360px,height=450px]{graphics/jointKinect.jpg} \\
	\textbf{Fuente:} \citeA[]{rocha2015kinect}
\end{figure}
\citeA{hernandez2013analisis}, señalan que el funcionamiento del seguimiento del esqueleto debe asociar los parámetros del cuerpo humano (e.g. Extremidades superiores, articulaciones o gestos), dichos parámetros son utilizado por un fotograma del esqueleto, cuya finalidad es reconocer el borde del cuerpo humano y posteriormente detectar cada parte del esqueleto humano a partir de los datos del esqueleto:
\begin{figure}[H]
	\caption{Arquitectura del seguimiento del esqueleto}
	\label{fig:skeletanTracking}
	\centering
	\includegraphics[width=450px,height=170px]{graphics/SkeletanTracking.jpg} \\
	\textbf{Fuente:} Propia
\end{figure}
En la figura \ref{fig:skeletanTracking} se observa que el seguimiento del esqueleto est\'a conformado por 6 pasos: 
\begin{enumerate}[1.]
    \item Como primer paso el Kinect escanea el ambiente constantemente.
    \item Posteriormente se crea el mapa de profundidad.
    \item Luego se detecta el suelo, se separa los objetos e identifica el contorno de cada jugador.
    \item Por cada jugador se le asigna un identificador  y después se clasifica las partes del cuerpo humano (e.g. cabeza, brazos, manos, piernas).
    \item Seguidamente a cada parte del cuerpo humano se le asigna una unión.
    \item Finalmente unifica cada unión en el orden correspondiente, tal como se observa en la figura \ref{fig:jointsKinect}.
\end{enumerate}
\medbreak
En cuanto a las uniones, \citeA{hernandez2013analisis} mencionan que cada unión se encuentra en un sistema diestro de coordenadas en donde cada eje (ejes X, Y y Z) representa la distancia (en metros) del Kinect a la uni\'on, tal como se representa en la figura \ref{fig:CoordenadaJoint}:
\begin{figure}[H]
	\caption{Sistema de coordenadas de la unión}
	\label{fig:CoordenadaJoint}
	\centering
	\includegraphics[width=225px,height=75px]{graphics/PartsToJoin.jpg} \\
	\textbf{Fuente:} Propia
\end{figure}
De acuerdo a la documentaci\'on de  \citeA{microsoftCoordinateMapper}, el seguimiento del esqueleto puede mapearse en una imagen de 2 dimensiones (ancho de 511 p\'ixeles y una altura de 423  p\'ixeles), a partir de una funci\'on llamada, map camera point to depth, la cual se encarga de transformar los puntos de altura y ancho de cada articulaci\'on (estructura del espacio del objeto), con la ayuda de la distancia de profundidad.