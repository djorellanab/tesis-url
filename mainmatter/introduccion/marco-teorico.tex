\section{MARCO TEÓRICO}
\subsection{C\'AMARA CON SENSOR DE PROFUNDIDAD}
Según el estudio, On the performance of the Intel SR300 depth camera: metrological and critical characterization \cite{carfagni2017performance}, menciona que unas de las principales funciones de las \acrfull{RGBD} es adquirir y procesar datos en \acrfull{TRESD}, estas cámaras se han utilizado en el sector industrial y académico en aplicaciones tales como: La localización y mapeo simultáneos, ingeniería inversa y reconocimiento de posiciones y gestos.
\medbreak
Por otro lado el estudio, RGB-D mapping: Using Kinect-style depth cameras for dense 3D modeling of indoor environments \cite{henry2012rgb}, indica que las cámaras con sensor de profundidad capturan \gls{pixeles} de información de imágenes (RGB) y de profundidad, tal como se muestra en la siguiente figura:
\begin{figure}[ht]
	\caption{Captura de datos de una cámara con sensor de profundidad}
	\label{fig:RGBD}
	\centering
	\includegraphics[]{graphics/RGB-D.PNG} \\
	\textbf{Fuente:} Tomado por el autor de tesis
\end{figure}  \\
La figura \ref{fig:RGBD}, fue capturado por el dispositivo, Kinect de XBox One, a una velocidad de 28 \acrfull{FPS}, cabe mencionar que los píxeles blancos de la imagen de la derecha, puede determinar variables de profundidad de un objeto tales como: distancia, mapeo, seguimiento (Tracking), sonido, entre otras variables más...
\subsubsection{Dispositivos en el mercado}
A continuación se presentará una lista de cámaras con sensor de profundidad, que se encuentra en el mercado hoy en día:
\begin{itemize}
	\item \textbf{ASUS XtionPro Live:} la corporación ASUSTeK Computer \cite{xtionAsus}, desarrolló una cámara con sensor de profundidad e infrarrojo, que permite detectar profundidad adaptativa, imagen en color y flujo de audio. Estas características permite capturar la imagen, el movimiento y la voz en tiempo real de un usuario. 
	\item \textbf{Structure Sensor:} La empresa, Occipital inc \cite{structureOccipital}, implementa un sensor de estructura, que permite escanear personas, espacios, mapas y objetos en 3D. 
	\item \textbf{Intel RealSense cameras:} Según la tecnología Intel RealSense \cite{intelRealSense}, permite detectar una alta velocidad de cuadros (píxeles), RGB de calidad y la mejor resolución de profundidad, en soluciones de realidad virtual, realidad aumentada, robótica, drones y otras aplicaciones más..
	\item \textbf{Microsoft Kinect:} Según el estudio, Microsoft Kinect Sensor and its effect	\cite{zhang2012microsoft}, menciona que el Kinect contiene un sensor de profundidad, una cámara a color y una matriz de micrófonos que permite capturar movimientos, reconocer características faciales, construir un modelo del cuerpo en 3D y reconocer sonidos.
\end{itemize}
Tal como se observa en el listado, todas las cámaras con RGB-D, permite detectar características del ambiente, sin embargo se puede diferenciar con las siguientes especificaciones:
\begin{figure}[ht]
	\caption{Especificaciones de una c\'amara con RGB-D}
	\label{fig:RGBESP}
	\centering
	\includegraphics[width=300px,height=300px]{graphics/RGBFeatures.png} \\
	\textbf{Fuente:} Tomado por el autor de tesis
\end{figure}
\medbreak
En la figura \ref{fig:RGBESP}, se muestra una vista general de las características de una cámara con RGB-D, entre ellas se puede observar el alcance máximo de profundidad (Alcance del sensor 3D). Así mismo se encuentra el \acrfull{FOV}, cuya finalidad es determinar el ángulo máximo de la cámara, respecto a los ejes: horizontal(H), vertical (V) y profundidad (D). Por otra parte, se encuentra la conexión de la cámara al dispositivo, cuya función es capturar los datos de entradas y salidas, como por ejemplo: la Resolución de colores e infrarrojo (Tal como se observa en la figura \ref{fig:RGBD}).
\medbreak
A continuación se presentará una comparación de las especificaciones entre las cámaras de RGB-D, mencionadas anteriormente:
\begin{table}[ht]
\begin{center}
\caption{Comparación de especificaciones entre cámaras de RGB-D }
\label{tab:RGBD}
\begin{tabular}{|l|l|l|l|l|l|} 
\hline
\textbf{Características}                                                          & \begin{tabular}[c]{@{}l@{}}\textbf{ASUS}\\\textbf{XtionPro}\\\textbf{Live}\end{tabular}   & \begin{tabular}[c]{@{}l@{}}\textbf{Structure}\\\textbf{Sensor}\end{tabular}  & \begin{tabular}[c]{@{}l@{}}\textbf{Intel}\\\textbf{RealSense}\\\textbf{SR300}\end{tabular}  & \begin{tabular}[c]{@{}l@{}}\textbf{Microsoft}\\\textbf{Kinect}\\\textbf{Live}\end{tabular} & \begin{tabular}[c]{@{}l@{}}\textbf{Microsoft}\\\textbf{Kinect}\\\textbf{v2}\end{tabular}	  \\ 
\hline
\begin{tabular}[c]{@{}l@{}}\textbf{Alcance del}\\\textbf{ sensor 3D}\end{tabular} & 0.8 a 3.5 m                                                                               & 0.4 a 3.5m                                                                   & 0.2 a 1.5m                                                                                  & 1.8 a 3.5m                                                                                 & 1.3 a 3.5m                                                                                  \\ 
\hline
\textbf{3D Resolución}                                                            &\begin{tabular}[c]{@{}l@{}}640x480\\30fps\end{tabular}                   & \begin{tabular}[c]{@{}l@{}}640x480\\30fps\end{tabular}     & \begin{tabular}[c]{@{}l@{}}640x480\\60fps\end{tabular}                    &\begin{tabular}[c]{@{}l@{}}320x240\\30fps\end{tabular}					& \begin{tabular}[c]{@{}l@{}}512x424\\30fps\end{tabular}                    \\ 
\hline
\begin{tabular}[c]{@{}l@{}}\textbf{RGB}\\\textbf{ Resolución}\end{tabular}        &\begin{tabular}[c]{@{}l@{}}1280x1024\\30fps\end{tabular}                   & \begin{tabular}[c]{@{}l@{}}640x480\\30fps\end{tabular}     & \begin{tabular}[c]{@{}l@{}}1920x1080\\30fps\end{tabular}                    &\begin{tabular}[c]{@{}l@{}}640x480\\30fps\end{tabular}					& \begin{tabular}[c]{@{}l@{}}1920x1080\\30fps\end{tabular}                    \\ 
\hline
\textbf{FOV}                                                                      & 58°H, 45°V                                                                                & 58°H, 45°V                                                                   & 73°H, 59°V                                                                                  & 57°H, 43°V                                                                                 & 70°H, 60°V                                                                                  \\ 
\hline
\textbf{Conexión}                                                                 & USB 2.0                                                                                   & USB 2.0                                                                      & USB 3.0                                                                                     & USB 2.0                                                                                    & USB 3.0                                                                                     \\
\hline
\end{tabular}
\end{center}
\textbf{Fuente:} Desarrollo de una aplicación interactiva con Intel RealSense \cite{molero2018desarrollo} y Evaluation of the spatial resolution accuracy of the face tracking system for kinect for windows v1 and v2 \cite{amon2014evaluation}
\end{table}
\medbreak
En la tabla \ref{tab:RGBD}, se puede determinar que la cámaras, Intel RealSense SR300 y Microsoft Kinect V2, destacan de las demás cámaras debido  que tiene una mayor resolución del sensor RGB y un campo de visión más amplio, por lo cual para el presente proyecto se seleccionará la cámara Microsoft Kinect V2. 
\subsubsection{Microsoft Kinect V2}
Según el libro, Kinect for Windows SDK Programming Guide \cite{jana2012kinect}, menciona que el dispositivo Kinect se realizó para la consola de videojuegos, Xbox 360, además proporciona una \acrfull{NUI}, que permite interactuar con el dispositivo, a partir de movimientos, gestos y sonidos (Tecnología con control de manos libres).
\medbreak
Por otra parte el autor, \citeA{jana2012kinect}, menciona que Microsoft desarrolló un \acrfull{SDK} para distintos lenguajes de programación, sin embargo, antes de empezar a codificar, es importante conocer la arquitectura del Kinect.
\paragraph{Componentes}\mbox{} \\
\begin{figure}[ht]
	\caption{Componentes del Kinect V2}
	\label{fig:COMPKINECT}
	\centering
	\includegraphics[width=400px,height=200px]{graphics/kinect-parts.PNG} \\
	\textbf{Fuente:} Tomado por el autor de tesis
\end{figure}
\medbreak
En la figura \ref{fig:COMPKINECT}, se muestra los componentes del Kinect que enlista el autor \citeA{jana2012kinect}, entre ellas se puede observar la cámara a color cuya función es capturar y transmitir los datos de vídeo en color, así mismo se encuentra el sensor de profundidad conformado por el emisor de infrarrojo, que se encarga de escanear el ambiente constantemente  y convertirlo en información a partir del sensor de profundidad infrarroja (Identificando así los objetos), también el Kinect puede rotar la imagen a partir de un pequeño motor que conecta la base y el cuerpo. Por otro lado la matriz de micrófonos permite capturar e identificar la dirección del sonido en el ambiente. Finalmente, se encuentra el  \acrfull{LED}, cuya tarea es identificar si los controladores del Kinect (IR, Seguimiento de objetos, RGB y sonido) están funcionando correctamente a partir de una luz blanca.
\paragraph{Conexión a la computadora}\mbox{} \\
\begin{figure}[ht]
	\caption{Adaptador del Kinect V2}
	\label{fig:ADAPTERKINECT}
	\centering
	\includegraphics[width=400px,height=200px]{graphics/adapter-kinect.jpg} \\
	\textbf{Fuente:} \citeA{Kinectmanual}
\end{figure}
\medbreak
Tal como se observa en la figura \ref{fig:ADAPTERKINECT}, el cable de conexión esta conformado por 5 partes: (1) el cable de datos del Kinect que se encarga de recibir los datos de entradas y salidas del sensor, así mismo esta (2) al adaptador del Kinect, que permite administrar los datos de entradas y salidas de la computadora y el sensor, a partir del (3) cable de USB 3. Cabe mencionar que dicho adaptador funciona con  un voltaje de 12 voltios y una corriente de 3 amperios que son administrado de una (4-5) fuente de alimentación  que regula una entrada de 100 a 240 voltios y una corriente de 1.6 amperios.
\paragraph{Kit de desarrollo de Software (SDK)}\mbox{} \\
Para el presente proyecto, se utilizará el SDK de la empresa  \citeA{SDKKinect}, que permite crear aplicaciones de reconocimientos de gestos y de voz con el sensor Kinect.
\subparagraph{Kinect v2 configuration verifier}\mbox{} \\
Dicha aplicación verifica y analiza el dispositivo que se encuentra conectado al sensor Kinect, tomando en cuenta las compatibilidades del hardware y la comunicación del dispositivo al sensor:
\begin{figure}[ht]
	\caption{Kinect v2 configuration verifier}
	\label{fig:KinectConfigurationVerifier}
	\centering
	\includegraphics[width=360px,height=360px]{graphics/kinect-configuration-verifier.PNG} \\
	\textbf{Fuente:} Tomado por el autor de tesis
\end{figure}
\medbreak
En la figura \ref{fig:ADAPTERKINECT}, se observa las siguientes validaciones:
\begin{itemize}
	\item \textbf{Update Configuration Definitions:} Verifica que tenga la última versión del SDK (2.0.1410.19000).
		\item \textbf{Operating System:} Verifica si el sistema operativo es compatible (Windows 8 o superior).
		\item \textbf{Processor Cores:} Detecta si el procesador tiene los suficientes números de core (Procesador rápido, como por ejemplo Intel 5).
		\item \textbf{Physical Memory (RAM):} Chequea si el dispositivo tiene la suficiente memoria (Mínimo 4GB de RAM).
		\item \textbf{Graphics Processor:} Verifica si el procesador gráfico es compatible con el SDK. (Directx 11).
		\item \textbf{USB Controller:} Verifica si el dispositivo reconoce el puerto de entrada (USB 3).	
		\item \textbf{Kinect Connected:} Detecta si el Sensor Kinect se encuentra conectado con el dispositivo.
		\item \textbf{Verify Kinect Software Installed:} Verifica las unidades (Drives) del sistema y el sensor (Sonido y cámara).
		\item \textbf{Verify Kinect Depth and Color Streams:} Verifica los sensores de profundidad y de color (RGB e IR).
\end{itemize}
\subparagraph{Kinect Studio}\mbox{} \\
Según el libro, Beginning Microsoft Kinect for Windows SDK 2.0: Motion and Depth Sensing for Natural User Interfaces \cite{rahman2017beginning}, menciona que Kinect Studio es una aplicación incluida en el SDK, que permite capturar y reproducir datos de kinect en formato de vídeo.\\
En dicha aplicación se observa la pestaña del monitor, encargada de transmitir los siguientes datos de análisis:
\begin{itemize}
	\item \textbf{Monitor NUI Body Frame:} Transmisión que contiene un espacio de almacenamiento para trabajar los datos de articulaciones del cuerpo.
	\item \textbf{Monitor NUI Body Index:} Transmisión que se encarga de clasificar y determinar los píxeles de cada objeto.
	\item \textbf{Monitor NUI Depth:} Transmisión que se encarga de trabajar los datos de profundidad (Eje Z).
	\item \textbf{Monitor NUI IR:} Transmisión que trabaja con una imagen infrarroja a partir de la técnica de \gls{TOF}.
	\item \textbf{Monitor NUI Title Audio:} Transmisión que suministra el audio capturado en todas las direcciones.
	\item \textbf{Monitor NUI uncompressed color:} Transmisión encargada de proporcionar los datos de la imagen a color.	
\end{itemize}
Así mismo, se encuentra la pestaña para grabar vídeo en formato, \acrfull{XEF},  cabe mencionar que dicho formato genera vídeo de gran tamaño debido a la cantidad de datos que son capturados, por lo cual se recomienda realizar varias repeticiones del movimiento en el menor tiempo posible y de igual manera capturar los siguientes datos, para el análisis del movimiento:
\medbreak
\begin{figure}[H]
	\caption{Diagrama de Venn para identificar la transmisión de datos del Kinect}
	\label{fig:VennStreaming}
	\centering
	\includegraphics[width=250px,height=250px]{graphics/venn-streaming.png} \\
	\textbf{Fuente:} Realizado por el autor de tesis
\end{figure}
\medbreak
En la figura \ref{fig:VennStreaming}, se puede concluir que la transmisión, body frame, trabaja independiente y para la identificación de los objetos son necesario las transmisiones: IR, Deep y Body Frame.
\medbreak
Finalmente en la figura \ref{fig:PlayKinectStudio}, puedes ver el resultado de un vídeo tomado por el Kinect Studio, cabe mencionar que Kinect Studio te proporciona varias herramienta  para analizar el vídeo, tales como: el punto de Inicio y Fin, cuya función es marcar una interacción, así mismo puede indicar el número de repeticiones de la interacción, además de colocar puntos de pausa y etiquetas de metadatos, que te permitirá almacenar información adicional en un punto específico del vídeo.
\begin{landscape}
 \begin{figure}[ht]
	\caption{Visualización del vídeo, Kinect Studio}
	\label{fig:PlayKinectStudio}
	\centering
	\includegraphics[width=660px,height=360px]{graphics/play-kinectstudio.png} \\
	\textbf{Fuente:} Tomado por el autor de tesis
\end{figure}
\end{landscape} 
\subparagraph{Visual Gesture Builder}\mbox{} \\
Según el autor, \citeA{rahman2017beginning}, menciona que la aplicación, \acrfull{VGB}, es una herramienta de aprendizaje automático (i.e. Machine learning), que permite crear una base de datos para reconocer gestos en tiempo de ejecución, cabe mencionar que la herramienta utiliza dos algoritmos para la detección de objetos, \acrfull{RFR} para modelos continuos, y \acrfull{AdaBoost} para modelos discretos. Así mismo, los algoritmos analiza las siguientes variables en función del tiempo:
\begin{itemize}
	\item Diferencia de posiciones.
	\item Ángulos de articulaciones y de movimientos.
	\item Velocidad de desplazamiento y angular.
	\item Aceleración de desplazamiento y angular.	
	\item Fuerza muscular
	\item Torque muscular
\end{itemize}
Por lo que se refiere al modelo AdaBoost el autor,  \citeA{AdaBoosting2018}, explica la técnica de Boosting, cuya funcionalidad es mejorar las predicciones del modelo, a partir de un número de entrenamientos secuenciales, tal como se observa la siguiente figura:
\begin{figure}[H]
	\caption{Técnica Boosting}
	\label{fig:AdaBoost}
	\centering
	\includegraphics[width=400px,height=200px]{graphics/AdaBoosting.png} \\
	\textbf{Fuente:} Realizado por el autor de tesis
\end{figure}
\medbreak
En la figura \ref{fig:AdaBoost}, se observa que en el entrenamiento \# 1,  los datos de entradas se encuentra muy dispersos, por lo tanto, cada dato de entrada se  debe entrenar a partir de un algoritmo de aprendizaje, que permitirá transformar una nueva función, tal como se observa el entrenamiento \# 2, los datos de entradas están más cercano. Cabe mencionar que se debe establecer los números de entrenamientos y el algoritmo de aprendizaje que utilizará por cada entrenamiento, siguiendo con el ejemplo de la figura \ref{fig:AdaBoost}, tiene un total de 2 entrenamientos, y cada entrenamiento consta de operar el dato de entrada por su respectiva regresión lineal y una constante.
\medbreak
Cabe mencionar que el modelo discreto, es recomendable utilizarlo para identificar movimientos estáticos (e.g. Identificar si la persona se encuentra sentada, arrodillada, entre otros movimientos más...), por lo que el software, VGB, permite analizar el vídeo (.xef) y posteriormente etiquetar los momentos que se encuentra realizando dicho movimientos estáticos:
\begin{figure}[H]
	\caption{Etiquetas de movimientos estático}
	\label{fig:modeloDiscreto}
	\centering
	\includegraphics[width=400px,height=350px]{graphics/modelo-discreto.png} \\
	\textbf{Fuente:} Realizado por el autor de tesis
\end{figure}
\medbreak
En la figura \ref{fig:modeloDiscreto}, se puede observar que en el panel de control puede etiquetar los valores: positivos (Barra azul arriba) y negativos (Barra azul abajo), así mismo se observa el movimiento estático, Manos abajo, que consta en identificar que ambas manos y brazos estén tocando la parte dorsal del cuerpo (i.e. Figura \ref{fig:modeloDiscreto}.B), en caso que este realizando otro movimiento, el valor de la etiqueta será falso (i.e.  Figura \ref{fig:modeloDiscreto}.C).
\medbreak
Por lo que se refiere al modelo Random Forest Regression, la autora, \citeA{RandomForestRegression2018}, menciona que este modelo realiza varios conjuntos de técnicas, entre ellas se encuentra las técnicas de regresiones, árboles de decisiones y una técnica llamada, Boostrap Aggregation, que consta en entrenar cada árbol de decisión, a partir de las variables de análisis, tal como se observa en la figura \ref{fig:RandomForestRegression}:
\begin{figure}[H]
	\caption{Técnica Random Forest Regression}
	\label{fig:RandomForestRegression}
	\centering
	\includegraphics[width=400px,height=200px]{graphics/random-forest-regression.png} \\
	\textbf{Fuente:} Realizado por el autor de tesis
\end{figure}
\medbreak
Finalmente, el modelo continuo es recomendable utilizarlo para identificar movimientos dinámicos (e.g. Sentadillas, abdominales, saltos, entre otros movimientos más...), tal como se observa en la siguiente figura:
\begin{figure}[H]
	\caption{Etiquetas de movimientos dinámicos}
	\label{fig:modeloContinuo}
	\centering
	\includegraphics[width=400px,height=350px]{graphics/modelo-continuo.png} \\
	\textbf{Fuente:} Realizado por el autor de tesis
\end{figure}
En la figura \ref{fig:modeloContinuo}, se esta analizando el movimiento de vuelo, la cual se conforma de tres movimientos estáticos: Brazos abajos (i.e. Figura \ref{fig:modeloContinuo}.B), brazos al medio (i.e. Figura \ref{fig:modeloContinuo}.C)  y brazos arriba (i.e. Figura \ref{fig:modeloContinuo}.D),  por lo tanto para analizar y detectar el movimiento dinámico, se etiqueta con un valor decimal a cada movimiento estático, tal como se observa en la figura, el primer paso del movimiento dinámico esta entre el valor de 0.00 a 0.33. 